{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Describtion\n",
    "- In this Notebook i'm going to demonstrate how to design an abstracted model to fit data using Linear Gaussian Mixture and Logistic Regression Models.\n",
    "- I will note how different systax or tools affect the speed of code.\n",
    "- I will demonstrate how to maximize training and testing accuracy.\n",
    "- #### *Outlines*:\n",
    "    - [Import Libraries](#import-libraries)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFetcher\n",
    "class DataFetcher:\n",
    "    \"\"\"\n",
    "    Parse training and testing data from specific dirctory\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, data_name, labels_name):\n",
    "        self.directory = directory\n",
    "        self.data_name = data_name\n",
    "        self.labels_name = labels_name\n",
    "\n",
    "    #Validate paramters \n",
    "    @property\n",
    "    def directory(self):\n",
    "        self._directory\n",
    "    \n",
    "    @directory.setter\n",
    "    def directory(self, string):\n",
    "        if type(string) != str:\n",
    "            raise ValueError(\"Invalid Input: Input must be string!\")\n",
    "        else:\n",
    "            self._directory = string\n",
    "\n",
    "    @property\n",
    "    def data_name(self):\n",
    "        self._data_name\n",
    "    \n",
    "    @data_name.setter\n",
    "    def data_name(self, string):\n",
    "        if type(string) != str:\n",
    "            raise ValueError(\"Invalid Input: Input must be string!\")\n",
    "        else:\n",
    "            self._data_name = string\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def labels_name(self):\n",
    "        self._labels_name\n",
    "    \n",
    "    @labels_name.setter\n",
    "    def labels_name(self, string):\n",
    "        if type(string) != str:\n",
    "            raise ValueError(\"Invalid Input: Input must be string!\")\n",
    "        else:\n",
    "            self._labels_name = string\n",
    "            \n",
    "    #get directory\n",
    "    def _get_training_data_path(self, subset_number):\n",
    "        return \"./%s/train%s%d.csv\" %(self._directory, self._data_name, subset_number+1)\n",
    "    \n",
    "    def _get_training_labels_path(self, subset_number):\n",
    "        return \"./%s/train%s%d.csv\" %(self._directory, self._labels_name, subset_number+1)\n",
    " \n",
    "    \n",
    "    def get_all_training_data(self):\n",
    "        training_data_dfs = []\n",
    "        training_labels_dfs = []\n",
    "\n",
    "        for subset in range(SUBSETS):\n",
    "            data_path = self._get_training_data_path(subset)\n",
    "            labels_path = self._get_training_labels_path(subset)\n",
    "\n",
    "            training_data_dfs.append(pd.read_csv(data_path, header=None))\n",
    "            training_labels_dfs.append(pd.read_csv(labels_path, header=None))\n",
    "\n",
    "        return training_data_dfs, training_labels_dfs\n",
    "    \n",
    "    def get_all_testing_data(self):\n",
    "\n",
    "        data_path = \"./%s/test%s.csv\" %(self._directory, self._data_name)\n",
    "        labels_path = \"./%s/test%s.csv\" %(self._directory, self._labels_name)\n",
    "\n",
    "        testing_data_df = pd.read_csv(data_path, header=None)\n",
    "        testing_labels_df = pd.read_csv(labels_path, header=None)\n",
    "\n",
    "        return testing_data_df, testing_labels_df\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CrossValidation:\n",
    "#     \"\"\"\n",
    "#     para*:\n",
    "#         data_dfs : list of folds*dataframe, each data frame is batch of m exambles\n",
    "#         labels_df : Dataframe contains sigle col which is labels\n",
    "#     \"\"\"\n",
    "#     def __init__(self, data_dfs, labels_dfs):\n",
    "#         assert(len(data_dfs) == len(labels_dfs))\n",
    "#         self.data_dfs = data_dfs\n",
    "#         self.labels_dfs = labels_dfs\n",
    "#         self.num_subsets = len(data_dfs)        \n",
    "\n",
    "#     def _split_dfs(self, dfs, subset):\n",
    "#         validation_df = dfs[subset]\n",
    "#         training_dfs = dfs[:subset] + dfs[subset+1:]\n",
    "\n",
    "#         training_df = pd.concat(training, ignore_index=True)\n",
    "\n",
    "#         return training_df, validation_df\n",
    "\n",
    "#     def _get_cross_validation(self, subset):\n",
    "#         training_x_set, validation_x_set =  _split_dfs(self.data_dfs, subset)\n",
    "#         training_y_set, validation_y_set = _split_dfs(self.labels_dfs, subset)\n",
    "         \n",
    "#         return training_x_set, training_y_set, validation_x_set, validation_y_set\n",
    "    \n",
    "#     def get_training_validation(self, subset):\n",
    "#         training_x, training_y, validation_x, validation_y = self._get_cross_validation(subset)\n",
    "\n",
    "#         return training_x, training_y, validation_x, validation_y\n",
    "    \n",
    "#     def get_training(self):\n",
    "#         training_x_set = pd.concat(self.data_dfs, ignore_index=True)\n",
    "#         training_y_set = pd.concat(self.labels_dfs, ignore_index=True)\n",
    "#         return training_x_set, training_y_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimized version of Cross validation\n",
    "class CrossValidation:\n",
    "    \"\"\"\n",
    "    para*:\n",
    "        data_dfs : list of folds*dataframe, each data frame is batch of m exambles\n",
    "        labels_df : Dataframe contains sigle col which is labels\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dfs, labels_dfs):\n",
    "        self.X = data_dfs\n",
    "        self.Y = labels_dfs\n",
    "        self.num_subsets = len(data_dfs)        \n",
    "\n",
    "    #split data\n",
    "    def _split_training_validation(self, dfs, subset):\n",
    "        validation_df = dfs[subset]\n",
    "        training_df = pd.concat(dfs[:subset] + dfs[subset+1:], ignore_index=True)\n",
    "        return [training_df, validation_df] \n",
    "    \n",
    "    def _get_x_training_validation(self, subset):\n",
    "        [training_X, validation_X] = self._split_training_validation(self.X, subset)\n",
    "        return [training_X, validation_X]\n",
    "\n",
    "    def _get_y_training_validation(self, subset):\n",
    "        [training_Y, validation_Y] = self._split_training_validation(self.Y, subset)\n",
    "        return [training_Y, validation_Y]\n",
    "\n",
    "    \n",
    "    def get_training_validation(self, subset):\n",
    "        [training_x, validation_x] = self._get_x_training_validation(subset)\n",
    "        [training_y, validation_y] = self._get_y_training_validation(subset)\n",
    "        return [training_x, training_y, validation_x, validation_y]\n",
    "        \n",
    "\n",
    "        return [training_x, training_y, validation_x, validation_y]\n",
    "    \n",
    "    def get_training(self):\n",
    "        training_x_set = pd.concat(self.X[:], ignore_index=True)\n",
    "        training_y_set = pd.concat(self.Y[:], ignore_index=True)\n",
    "        return [training_x_set, training_y_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ABC):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "    \n",
    "    def predict_df(self, x_df):\n",
    "        predictios = x_df.apply(lambda row: self.predict(row), raw=True, axis=1)\n",
    "        return predictios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_accuracy(true_labels, predicted_labels):\n",
    "#     assert(len(true_labels) == len(predicted_labels))\n",
    "#     return sum(1 for y, y_hat in zip(true_labels, predicted_labels) if y == y_hat ) / len(true_labels)\n",
    "\n",
    "def get_accuracy(true_labels, predicted_labels):\n",
    "    assert(len(true_labels) == len(predicted_labels))\n",
    "    return np.sum(true_labels ==  predicted_labels) / len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'knn-dataset'\n",
    "name_x = 'Data'\n",
    "name_y = 'Labels'\n",
    "SUBSETS = 10\n",
    "POSITIVE_LABEL = 5\n",
    "NEGATIVE_LABEL = 6\n",
    "\n",
    "DF = DataFetcher(directory, name_x, name_y)\n",
    "testing_X, testing_Y = DF.get_all_testing_data()\n",
    "training_X, training_Y = DF.get_all_training_data()\n",
    "\n",
    "CV = CrossValidation(training_X, training_Y)\n",
    "tr_x, tr_y = CV.get_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixture(Model):\n",
    "    def __init__(self, training_x, training_y, POSITIVE_LABEL, NEGATIVE_LABEL):\n",
    "        super().__init__(training_x, training_y)\n",
    "        self.POSITIVE_LABEL = POSITIVE_LABEL\n",
    "        self.NEGATIVE_LABEL = NEGATIVE_LABEL\n",
    "\n",
    "        #pi, mu_1, mu_2, s1, s2, cov, cov_inv, w0, w1\n",
    "        \n",
    "        #N1(number of points for class 1)\n",
    "        #N2(number of points for class 2)\n",
    "        #N(number of points for both classes)\n",
    "\n",
    "        #Dealing with flatten values in list is much faster than numpy array  \n",
    "        # y_list = training_y.values.flatten().tolist()\n",
    "        # pi = sum([1 if  i == self.POSITIVE_LABEL  else 0 for i in y_list ]) / len(y_list)\n",
    "        \n",
    "        pi = np.sum(training_y.to_numpy() == POSITIVE_LABEL) / len(training_y)\n",
    "\n",
    "        positive_indices = np.where(tr_y.to_numpy() == POSITIVE_LABEL)\n",
    "        negative_indices = np.where(tr_y.to_numpy() == NEGATIVE_LABEL)\n",
    "\n",
    "        #positive_indices = [index for index, i in enumerate(y_list) if i == POSITIVE_LABEL]    #get indices of positive labels\n",
    "        #negative_indices = [index for index, i in enumerate(y_list) if i == NEGATIVE_LABEL]    #get indices of negative labels\n",
    "\n",
    "        N1 = len(positive_indices)  #Length of positive items \n",
    "        N2 = len(negative_indices)  #Length of negetive items \n",
    "        N = N1 + N2                 #Length of all items\n",
    "\n",
    "        positive_x = training_x.iloc[positive_indices[0]].to_numpy()\n",
    "        negative_x = training_x.iloc[negative_indices[0]].to_numpy()\n",
    "\n",
    "        mu1 = positive_x.mean(axis=0)   #mean over cols, so broadcasting is done (500, 64)\n",
    "        mu2 = negative_x.mean(axis=0)\n",
    "\n",
    "\n",
    "        positive_x_dists = positive_x - mu1\n",
    "        negative_x_dists = negative_x - mu2\n",
    "\n",
    "        s1 = positive_x_dists.T.dot(positive_x_dists)/N1\n",
    "        s2 = negative_x_dists.T.dot(negative_x_dists)/N2\n",
    "\n",
    "        cov = ((N1/N) * s1) + ((N2/N) * s2)\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "\n",
    "        w = cov_inv.dot(mu1 - mu2)\n",
    "        w0 =  -(1/2) * mu1.T.dot(cov_inv).dot(mu1) + (1/2) * mu2.T.dot(cov_inv).dot(mu2) + np.log(pi/ (1-pi))\n",
    "\n",
    "        self.pi = pi \n",
    "        self.mu1 = mu1\n",
    "        self.mu2 = mu2 \n",
    "        self.N1 = N1\n",
    "        self.N2 = N2\n",
    "        self.cov = cov\n",
    "        self.cov_inv = cov_inv \n",
    "        self.w = w \n",
    "        self.w0 = w0 \n",
    "\n",
    "    def predict_prob(self, x):\n",
    "        logits = self.w.dot(x) + self.w0\n",
    "        prob = 1 / (1 + np.exp(-logits))\n",
    "        return prob\n",
    "    \n",
    "    def predict(self, x):\n",
    "        prob = self.predict_prob(x)\n",
    "        if prob > 0.5:\n",
    "            return self.POSITIVE_LABEL\n",
    "        else:\n",
    "            return self.NEGATIVE_LABEL\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Training and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy: 0.884000\nTest Accuracy: 0.890909\nTraining Time: 0.00398707389831543\n"
     ]
    }
   ],
   "source": [
    "# Create hypothesis\n",
    "t1 = time.time()\n",
    "GMM = GaussianMixture(tr_x, tr_y, POSITIVE_LABEL, NEGATIVE_LABEL)\n",
    "t2 = time.time()\n",
    "\n",
    "# Training Accuracy\n",
    "predicted_train_y = GMM.predict_df(tr_x)\n",
    "train_accuracy = get_accuracy(tr_y.values.flatten(), predicted_train_y.to_numpy())\n",
    "\n",
    "# Test Accuracy\n",
    "predicted_test_y = GMM.predict_df(testing_X)\n",
    "test_accuracy = get_accuracy(testing_Y.values.flatten(), predicted_test_y.values.flatten())\n",
    "\n",
    "print(\"Train Accuracy: %f\" % train_accuracy)\n",
    "print(\"Test Accuracy: %f\" % test_accuracy)\n",
    "print(\"Training Time: \" + str(t2-t1))"
   ]
  },
  {
   "source": [
    "## Logistic Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticRegression(Model):\n",
    "    def __init__(self, training_x, training_y, PositiveLabel, NegativeLabel, lmbda):\n",
    "        super().__init__(training_x, training_y, PositiveLabel, NegativeLabel)\n",
    "\n",
    "        self.X = training_x.to_numpy()\n",
    "        self.Y = training_y.to_numpy()\n",
    "\n",
    "        self.w = np.zeros(self.X.shape[1], 1)\n",
    "        self.R = self._sigmoid(self.X.dot(self.w)).dot((1-self.X.dot(self.w)).T)\n",
    "\n",
    "\n",
    "    def _R(self, x, w):\n",
    "        cita = x.dot(w)\n",
    "        cita_1 = (1-cita)\n",
    "        left_part = self._sigmoid(cita)\n",
    "        right_part = self._sigmoid(1-cita)\n",
    "        r = left_part.dot(right_part.T)\n",
    "        return r \n",
    "\n",
    "    def _hassian(self, x, w):\n",
    "        r = self._R(x, w)\n",
    "        h = x.T.dot(r).dot(x)\n",
    "        return h\n",
    "    \n",
    "    def _gradient(self, x, w, y):\n",
    "        cita = x.dot(w)\n",
    "        sig_part = self._sigmoid(cita)\n",
    "        left_part = sig_part- y\n",
    "        return left_part.T.dot(x)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        logit = 1 / (1 + np.exp(-x))\n",
    "        return logit\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#### Problem-1: Validate class parameters to meet some limitation\n",
    "- We will use ```@property``` decorator; a pythonic way to use getters and setters in object-oriented programming.\n",
    "- Look at [Validate Class Example](#validate-class-example).\n",
    "- #### References:\n",
    "    - [Here]()\n",
    "    - A good [tutorial](https://www.toptal.com/python/python-class-attributes-an-overly-thorough-guide) to class attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Validate Class Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this example i'm gonna demonstrate the pythonic OOP way to validate instance atrributes\n",
    "\"\"\"\n",
    "class DataSetterTest:\n",
    "    def __init__(self, name, number):\n",
    "        self._name = self._number = None\n",
    "        #set attributes use Setter method\n",
    "        self.set_name(name)\n",
    "        self.set_number(number)\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        if not type(name) == str: \n",
    "            raise ValueError(\"Invalid input , it must be a string\") \n",
    "        else:\n",
    "            self._name = name\n",
    "\n",
    "    def set_number(self, val):\n",
    "        if not ((type(val) == int ) or (type(val) == float)):\n",
    "            print(\"Invalid input , it must be a float'\")\n",
    "        else:\n",
    "            self._number = val\n",
    "        \n",
    "            \n",
    "    #get attributes use Setter method\n",
    "    def get_name(self):\n",
    "        if self._name is None: return ('Attribute has not been set')\n",
    "        else: return self._name\n",
    "    \n",
    "    def get_number(self):\n",
    "        if self._number is None: return ('Attribute has not been set')\n",
    "        else: return self._number\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_name': 'Mohamed', '_number': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "ins_ds = DataSetterTest('Mohamed', 1)\n",
    "ins_ds.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_ds.set_number(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_name': 'Mohamed', '_number': 7}"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "ins_ds.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this example i'm gonna demonstrate the pythonic OOP way to validate instance atrributes\n",
    "[Use toturial](https://www.datacamp.com/community/tutorials/property-getters-setters)\n",
    "\"\"\"\n",
    "class DataSetterTest:\n",
    "    def __init__(self, name, number):\n",
    "        self.name = name\n",
    "        self.number = number\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        if self._name == None : raise ValueError(\"Valid input, Empety set\")\n",
    "        return self._name\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, str_val):\n",
    "        if not (type(str_val) == str):\n",
    "            raise ValueError(\"Invalid input , it must be a string!\")\n",
    "        self._name = str_val\n",
    "    \n",
    "    @property\n",
    "    def number(self):\n",
    "        if self._number == None : raise ValueError(\"Valid input, Empety set\")\n",
    "        return self._number\n",
    "    \n",
    "    @number.setter\n",
    "    def number(self, val):\n",
    "        if not ((type(val) == int ) or (type(val) == float)):\n",
    "            raise ValueError(\"Invalid input , it must be a Number!\")\n",
    "        self._number = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_name': 'Mohamed', '_number': 11}"
      ]
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "instance_DS = DataSetterTest(\"Mohamed\", 11)\n",
    "instance_DS.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_name': 'Mohamed', '_number': 11}"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "instance_DS.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Example(object):\n",
    "    def __init__(self, nr1, nr2):\n",
    "        self.a = nr1\n",
    "        self.b = nr2\n",
    "\n",
    "    def Add(self):\n",
    "        c = self.a + self.b\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_ex = Example(1, 2)\n",
    "x = ins_ex.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "ins_ex.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(object):\n",
    "    def __init__(self, nr1, nr2):\n",
    "        self.a = nr1\n",
    "        self.b = nr2\n",
    "\n",
    "    def Add(self):\n",
    "        self.c = self.a + self.b\n",
    "        return self.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3}"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "ins_ex = Example(1, 2)\n",
    "x = ins_ex.Add()\n",
    "ins_ex.__dict__"
   ]
  },
  {
   "source": [
    "### Class attributes vs instance attributes using both mutable and immutable objects"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassVar:\n",
    "\n",
    "    global_immutable_class_variable = 45\n",
    "    global_mutable_class_variable = [1, 2, 3]\n",
    "\n",
    "\n",
    "    def __init__(self, mutable_parameter, immutable_parameter):\n",
    "        self.mutable_instance_attribute = mutable_parameter\n",
    "        self.immutable_instance_attribute = immutable_parameter\n",
    "    \n",
    "    def set_property(self, new_val):\n",
    "        global_immutable_class_variable = new_val\n",
    "        global_mutable_class_variable.append(new_val)\n",
    "        self.immutable_instance_var = 0\n",
    "        self.mutable_instance_var.append(new_val)\n",
    "    \n",
    "    def get_property(self):\n",
    "        try:\n",
    "            print(\"Out of the Excption\")\n",
    "            print(\"global immutable class variable \", global_immutable_class_variable)\n",
    "            print(\"global mutable class variable \", global_mutable_class_variable)\n",
    "        except:\n",
    "            print(\"From Excption\")\n",
    "            print(\"global immutable class variable \", ClassVar.global_immutable_class_variable)\n",
    "            print(\"global mutable class variable \", ClassVar.global_mutable_class_variable)\n",
    "        print(\"immutable instance attribute \", self.immutable_instance_attribute)\n",
    "        print(\"mutable instance attribute \", self.mutable_instance_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1 = ClassVar([10, 20, 30], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "From Excption\nglobal immutable class variable  45\nglobal mutable class variable  [1, 2, 3]\nimmutable instance attribute  100\nmutable instance attribute  [10, 20, 30]\n"
     ]
    }
   ],
   "source": [
    "instance1.get_property()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'mutable_instance_attribute': [10, 20, 30],\n",
       " 'immutable_instance_attribute': 100}"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "instance1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__',\n",
       "              'global_immutable_class_variable': 45,\n",
       "              'global_mutable_class_variable': [1, 2, 3],\n",
       "              '__init__': <function __main__.ClassVar.__init__(self, mutable_parameter, immutable_parameter)>,\n",
       "              'set_property': <function __main__.ClassVar.set_property(self, new_val)>,\n",
       "              'get_property': <function __main__.ClassVar.get_property(self)>,\n",
       "              '__dict__': <attribute '__dict__' of 'ClassVar' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'ClassVar' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "ClassVar.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1.global_mutable_class_variable.append(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1, 2, 3, 40, 40]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "instance1.global_mutable_class_variable"
   ]
  },
  {
   "source": [
    "### Problem-2\n",
    "Performance of Numpy Array vs Python List\n",
    "```Python\n",
    "y_list = tr_y.values.flatten().tolist()\n",
    "sum([1 if y == 5 else 0 for y in y_list]) / len(y_list)\n",
    "```\n",
    "is faster than \n",
    "```\n",
    "arr = tr_y.to_numpy()\n",
    "sum([1 for i in arr if i == 5 ])/arr.__len__()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "this happend because of that numpy has to wrap the returned object with a python type (e.g. numpy.float64 or numpy.int64 in this case) which takes time if you're iterating item-by-item1. Further proof of this is demonstrated when iterating -- We see that we're alternating between 2 separate IDs while iterating over the array. This means that python's memory allocator and garbage collector are working overtime to create new objects and then free them.\n",
    "\n",
    "A list doesn't have this memory allocator/garbage collector overhead. The objects in the list already exist as python objects (and they'll still exist after iteration), so neither plays any role in the iteration over a list. \n",
    "\n",
    "[Stackoverflow reference](https://stackoverflow.com/questions/35232406/why-is-a-for-over-a-python-list-faster-than-over-a-numpy-array)\n",
    "\n",
    "After some investigation \n",
    "\n",
    "Using NumPy like that is like dragging your car behind you by hand as you walk to the store - you're not actually using the power of the tools at your disposal.\n",
    "```\n",
    "np.sum(tr_y.labels.to_numpy()==5)/len(tr_y)\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17.2 µs ± 237 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sum(tr_y.to_numpy()==5)/len(tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "82.3 µs ± 3.31 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum([1 for i in tr_y.to_numpy().tolist() if i == 5 ])/arr.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60.7 µs ± 1.97 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum([1 for i in tr_y.values.flatten().tolist() if i == 5 ])/arr.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.03 ms ± 16.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum([1 for i in tr_y.to_numpy() if i == 5 ])/arr.__len__()"
   ]
  },
  {
   "source": [
    "Check my [Question](https://stackoverflow.com/questions/66313883/performance-of-numpy-array-vs-python-list-over-1d-matrixvector?noredirect=1#comment117239143_66313883) on stackoverflow"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### How i get indices of class using numpy\n",
    "- Method using python \n",
    "```\n",
    "positive_indices = [index for index, i in enumerate(y_list) if i == POSITIVE_LABEL]\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "89.2 µs ± 4.73 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "y_list = tr_y.values.flatten().tolist()\n",
    "positive_indices = [index for index, i in enumerate(y_list) if i == POSITIVE_LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17.2 µs ± 1.22 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "positive_indices_np = np.where(tr_y.to_numpy()==POSITIVE_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = tr_x.iloc[positive_indices_np[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "execution_count": 482
    }
   ],
   "source": [
    "pos_df.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "execution_count": 502
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-4.846, -4.902,  0.72 , ..., -3.198, -5.002, 11.056],\n",
       "       [-4.846, -4.902, -8.28 , ..., -6.198, -5.002, -4.944],\n",
       "       [ 9.154,  4.098,  7.72 , ...,  1.802,  9.998,  7.056],\n",
       "       ...,\n",
       "       [-4.846, -4.902, -8.28 , ..., -6.198, -5.002, -4.944],\n",
       "       [-4.846, -4.902, -8.28 , ..., -6.198, -5.002, -4.944],\n",
       "       [-4.846, -4.902, -8.28 , ..., -6.198, -5.002, -4.944]])"
      ]
     },
     "metadata": {},
     "execution_count": 510
    }
   ],
   "source": [
    "mu = (pos_df.to_numpy()).mean(axis=0)\n",
    "pos_ndarray = pos_df.to_numpy()\n",
    "pos_ndarray - mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Int64Index([0], dtype='int64')"
      ]
     },
     "metadata": {},
     "execution_count": 493
    }
   ],
   "source": [
    "tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "metadata": {},
     "execution_count": 509
    }
   ],
   "source": [
    "mu = (pos_df.to_numpy()).mean(axis=0)\n",
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y_2 = np.copy(tr_y.to_numpy())\n",
    "tr_y_2[:100] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "metadata": {},
     "execution_count": 549
    }
   ],
   "source": [
    "np.sum(tr_y.to_numpy() == tr_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}