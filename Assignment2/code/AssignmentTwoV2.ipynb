{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Describtion\n",
    "- In this Notebook i'm going to demonstrate how to design an abstracted model to fit data using Linear Gaussian Mixture and Logistic Regression Models.\n",
    "- I will note how different systax or tools affect the speed of code.\n",
    "- I will demonstrate how to maximize training and testing accuracy.\n",
    "- #### *Outlines*:\n",
    "    - [Import Libraries](#import-libraries)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFetcher\n",
    "class DataFetcher:\n",
    "    \"\"\"\n",
    "    Parse training and testing data from specific dirctory\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, data_name, labels_name):\n",
    "        self.directory = directory\n",
    "        self.data_name = data_name\n",
    "        self.labels_name = labels_name\n",
    "\n",
    "    #Validate paramters \n",
    "    @property\n",
    "    def directory(self):\n",
    "        self._directory\n",
    "    \n",
    "    @directory.setter\n",
    "    def directory(self, string):\n",
    "        if type(string) != str:\n",
    "            raise ValueError(\"Invalid Input: Input must be string!\")\n",
    "        else:\n",
    "            self._directory = string\n",
    "\n",
    "    @property\n",
    "    def data_name(self):\n",
    "        self._data_name\n",
    "    \n",
    "    @data_name.setter\n",
    "    def data_name(self, string):\n",
    "        if type(string) != str:\n",
    "            raise ValueError(\"Invalid Input: Input must be string!\")\n",
    "        else:\n",
    "            self._data_name = string\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def labels_name(self):\n",
    "        self._labels_name\n",
    "    \n",
    "    @labels_name.setter\n",
    "    def labels_name(self, string):\n",
    "        if type(string) != str:\n",
    "            raise ValueError(\"Invalid Input: Input must be string!\")\n",
    "        else:\n",
    "            self._labels_name = string\n",
    "            \n",
    "    #get directory\n",
    "    def _get_training_data_path(self, subset_number):\n",
    "        return \"./%s/train%s%d.csv\" %(self._directory, self._data_name, subset_number+1)\n",
    "    \n",
    "    def _get_training_labels_path(self, subset_number):\n",
    "        return \"./%s/train%s%d.csv\" %(self._directory, self._labels_name, subset_number+1)\n",
    " \n",
    "    \n",
    "    def get_all_training_data(self):\n",
    "        training_data_dfs = []\n",
    "        training_labels_dfs = []\n",
    "\n",
    "        for subset in range(SUBSETS):\n",
    "            data_path = self._get_training_data_path(subset)\n",
    "            labels_path = self._get_training_labels_path(subset)\n",
    "\n",
    "            training_data_dfs.append(pd.read_csv(data_path, header=None))\n",
    "            training_labels_dfs.append(pd.read_csv(labels_path, header=None))\n",
    "\n",
    "        return training_data_dfs, training_labels_dfs\n",
    "    \n",
    "    def get_all_testing_data(self):\n",
    "\n",
    "        data_path = \"./%s/test%s.csv\" %(self._directory, self._data_name)\n",
    "        labels_path = \"./%s/test%s.csv\" %(self._directory, self._labels_name)\n",
    "\n",
    "        testing_data_dfs = pd.read_csv(data_path, header=None)\n",
    "        testing_labels_dfs = pd.read_csv(labels_path, header=None)\n",
    "\n",
    "        return testing_data_dfs, testing_labels_dfs\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'knn-dataset'\n",
    "name_x = 'Data'\n",
    "name_y = 'Labels'\n",
    "SUBSETS = 10\n",
    "DF = DataFetcher(directory, name_x, name_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_X, testing_Y = DF.get_all_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidation:\n",
    "    \"\"\"\n",
    "    para*:\n",
    "        data_dfs : list of folds*dataframe, each data frame is batch of m exambles\n",
    "        labels_df : Dataframe contains sigle col which is labels\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dfs, labels_dfs):\n",
    "        self.data_dfs = data_dfs\n",
    "        self.labels_dfs = labels_dfs\n",
    "        self.num_subsets = len(data_dfs)        \n",
    "\n",
    "    \n",
    "    def _get_cross_validation(self, subset):\n",
    "        validation_x_set = self.data_dfs[subset]\n",
    "        validation_y_set = self.labels_dfs[subset]\n",
    "\n",
    "        training_x_set = self.data_dfs[:subset]+self.data_dfs[subset+1:]\n",
    "        training_y_set = self.labels_dfs[:subset]+self.data_dfs[subset+1:]\n",
    "        return training_x_set, training_y_set, validation_x_set, validation_y_set\n",
    "    \n",
    "    def get_training_validation(self, subset):\n",
    "        training_x, training_y, validation_x, validation_y = self._get_cross_validation(subset)\n",
    "\n",
    "        training_x = pd.concat(training_x, ignore_index=True)\n",
    "        training_y = pd.concat(training_y, ignore_index=True)\n",
    "\n",
    "        return [training_x, training_y, validation_x, validation_y]\n",
    "    \n",
    "    def get_training(self):\n",
    "        training_x_set = pd.concat(self.data_dfs[:], ignore_index=True)\n",
    "        training_y_set = pd.concat(self.labels_dfs[:], ignore_index=True)\n",
    "        return [training_x_set, training_y_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimized version of Cross validation\n",
    "class CrossValidation_V2:\n",
    "    \"\"\"\n",
    "    para*:\n",
    "        data_dfs : list of folds*dataframe, each data frame is batch of m exambles\n",
    "        labels_df : Dataframe contains sigle col which is labels\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dfs, labels_dfs):\n",
    "        self.X = data_dfs\n",
    "        self.Y = labels_dfs\n",
    "        self.num_subsets = len(data_dfs)        \n",
    "\n",
    "    #split data\n",
    "    def _split_training_validation(self, dfs, subset):\n",
    "        validation_df = dfs[subset]\n",
    "        training_dfs = pd.concat(dfs[:subset] + dfs[subset+1:], ignore_index=True)\n",
    "        return [training_dfs, validation_df] \n",
    "    \n",
    "    def _get_x_training_validation(self, subset):\n",
    "        [training_X, validation_X] = self._split_training_validation(self.X, subset)\n",
    "        return [training_X, validation_X]\n",
    "\n",
    "    def _get_y_training_validation(self, subset):\n",
    "        [training_Y, validation_Y] = self._split_training_validation(self.Y, subset)\n",
    "        return [training_Y, validation_Y]\n",
    "\n",
    "    \n",
    "    def get_training_validation(self, subset):\n",
    "        [training_x, validation_x] = self._get_x_training_validation(subset)\n",
    "        [training_y, validation_y] = self._get_y_training_validation(subset)\n",
    "        return [training_x, training_y, validation_x, validation_y]\n",
    "        \n",
    "\n",
    "        return [training_x, training_y, validation_x, validation_y]\n",
    "    \n",
    "    def get_training(self):\n",
    "        training_x_set = pd.concat(self.data_dfs[:], ignore_index=True)\n",
    "        training_y_set = pd.concat(self.labels_dfs[:], ignore_index=True)\n",
    "        return [training_x_set, training_y_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_X, training_Y = DF.get_all_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CrossValidation_V2(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x, tr_y, tst_x, tst_y = CV.get_training_validation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ABC):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "    \n",
    "    def predict_df(self, x_df):\n",
    "        predictios = x_df.apply(lambda row: self.predict(row), raw=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(true_labels, predicted_labels):\n",
    "    assert(len(true_labels) == len(predicted_labels))\n",
    "    return sum(1 for y, y_hat in zip(true_labels, predicted_labels) if y == y_hat ) / len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixture(Model):\n",
    "    def __init__(self, training_x, training_y, POSITIVE_LABEL, NEGATIVE_LABEL):\n",
    "        super().__init__(training_x, training_y)\n",
    "        self.POSITIVE_LABEL = POSITIVE_LABEL\n",
    "        self.NEGATIVE_LABEL = NEGATIVE_LABEL\n",
    "\n",
    "        #pi, mu_1, mu_2, s1, s2, cov, cov_inv, w0, w1\n",
    "        y_list = training_Y.values.flatten().tolist()\n",
    "        pi = sum([1 if  i == self.POSITIVE_LABEL  else 0 for i in y_list 0])/len(y_list)\n",
    "\n",
    "        #N1(number of points for class 1)\n",
    "        #N2(number of points for class 2)\n",
    "        #N(number of points for both classes)\n",
    "        positive_indices = [index for index, i in enumerate(y_list) if i == self.POSITIVE_LABEL]\n",
    "        negative_indices = [index for index, i in enumerate(y_list) if i == self.NEGATIVE_LABEL]\n",
    "\n",
    "        N1 = len(positive_indices)\n",
    "        N2 = len(negative_indices)\n",
    "        N = N1 + N2\n",
    "\n",
    "        positive_x_df = training_x.iloc(positive_indices)\n",
    "        negative_x_df = training_x.iloc(negative_indices)\n",
    "\n",
    "        mu1 = positive_x_df.mean()\n",
    "        mu2 = negative_x_df.mean()\n",
    "\n",
    "        positive_x = positive_x_df.to_numpy()\n",
    "        negative_x = negative_x_df.to_numpy()\n",
    "\n",
    "        positive_x_dists = positive_x - mu1\n",
    "        negative_x_dists = negative_x - mu2\n",
    "\n",
    "        s1 = positive_x_dists.T.dot(positive_x_dists)/N1\n",
    "        s1 = negative_x_dists.T.dot(negative_x_dists)/N2\n",
    "\n",
    "        cov = ((N1/N) * s1) + ((N2/N) * s2)\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "\n",
    "        w = cov_inv.dot(mu1 - mu2)\n",
    "        w0 =  -(1/2) * mu1.T.dot(cov_inv).dot(mu1) + (1/2) * mu2.T.dot(cov_inv).dot(mu2) + np.log(pi/ (1-pi))\n",
    "\n",
    "        self.pi = pi \n",
    "        self.mu1 = mu1\n",
    "        self.mu2 = mu2 \n",
    "        self.N1 = N1\n",
    "        self.N2 = N2\n",
    "        self.cov = cov\n",
    "        self.cov_inv = cov_inv \n",
    "        self.w = w \n",
    "        self.w0 = w0 \n",
    "\n",
    "    def predict_prob(self, x):\n",
    "        logits = self.w.dot(x) + self.w0\n",
    "        prob = 1 / 1 + np.exp(-logits)\n",
    "        return prob\n",
    "    \n",
    "    def predict(self, x):\n",
    "        prob = self.predict_prob(x)\n",
    "        if prob > 0.5:\n",
    "            return self.POSITIVE_LABEL\n",
    "        else:\n",
    "            return self.NEGATIVE_LABEL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x, tr_y, tst_x, tst_y = CV.get_training_validation(3)\n",
    "c1_x = [index for index, i in enumerate(tr_y.to_numpy()) if i == 5]\n",
    "c2_x = [index for index, i in enumerate(tr_y.to_numpy()) if i == 6]\n",
    "pd.iloc(positive_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "871 µs ± 13.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "arr = tr_y.to_numpy()\n",
    "sum([1 for i in arr if i == 5 ])/arr.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "102 µs ± 1.4 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "y_list = tr_y.values.flatten().tolist()\n",
    "sum([1 if y == 5 else 0 for y in y_list]) / len(y_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#### Problem-1: Validate class parameters to meet some limitation\n",
    "- We will use ```@property``` decorator; a pythonic way to use getters and setters in object-oriented programming.\n",
    "- Look at [Validate Class Example](#validate-class-example).\n",
    "- #### References:\n",
    "    - [Here]()\n",
    "    - A good [tutorial](https://www.toptal.com/python/python-class-attributes-an-overly-thorough-guide) to class attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Validate Class Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this example i'm gonna demonstrate the pythonic OOP way to validate instance atrributes\n",
    "\"\"\"\n",
    "class DataSetterTest:\n",
    "    def __init__(self, name, number):\n",
    "        self._name = self._number = None\n",
    "        #set attributes use Setter method\n",
    "        self.set_name(name)\n",
    "        self.set_number(number)\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        if not type(name) == str: \n",
    "            raise ValueError(\"Invalid input , it must be a string\") \n",
    "        else:\n",
    "            self._name = name\n",
    "\n",
    "    def set_number(self, val):\n",
    "        if not ((type(val) == int ) or (type(val) == float)):\n",
    "            print(\"Invalid input , it must be a float'\")\n",
    "        else:\n",
    "            self._number = val\n",
    "        \n",
    "            \n",
    "    #get attributes use Setter method\n",
    "    def get_name(self):\n",
    "        if self._name is None: return ('Attribute has not been set')\n",
    "        else: return self._name\n",
    "    \n",
    "    def get_number(self):\n",
    "        if self._number is None: return ('Attribute has not been set')\n",
    "        else: return self._number\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_name': 'Mohamed', '_number': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "ins_ds = DataSetterTest('Mohamed', 1)\n",
    "ins_ds.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_ds.set_number(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_name': 'Mohamed', '_number': 7}"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "ins_ds.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this example i'm gonna demonstrate the pythonic OOP way to validate instance atrributes\n",
    "[Use toturial](https://www.datacamp.com/community/tutorials/property-getters-setters)\n",
    "\"\"\"\n",
    "class DataSetterTest:\n",
    "    def __init__(self, name, number):\n",
    "        self.name = name\n",
    "        self.number = number\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        if self._name == None : raise ValueError(\"Valid input, Empety set\")\n",
    "        return self._name\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, str_val):\n",
    "        if not (type(str_val) == str):\n",
    "            raise ValueError(\"Invalid input , it must be a string!\")\n",
    "        self._name = str_val\n",
    "    \n",
    "    @property\n",
    "    def number(self):\n",
    "        if self._number == None : raise ValueError(\"Valid input, Empety set\")\n",
    "        return self._number\n",
    "    \n",
    "    @number.setter\n",
    "    def number(self, val):\n",
    "        if not ((type(val) == int ) or (type(val) == float)):\n",
    "            raise ValueError(\"Invalid input , it must be a Number!\")\n",
    "        self._number = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_name': 'Mohamed', '_number': 11}"
      ]
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "instance_DS = DataSetterTest(\"Mohamed\", 11)\n",
    "instance_DS.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_name': 'Mohamed', '_number': 11}"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "instance_DS.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Example(object):\n",
    "    def __init__(self, nr1, nr2):\n",
    "        self.a = nr1\n",
    "        self.b = nr2\n",
    "\n",
    "    def Add(self):\n",
    "        c = self.a + self.b\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_ex = Example(1, 2)\n",
    "x = ins_ex.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "ins_ex.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(object):\n",
    "    def __init__(self, nr1, nr2):\n",
    "        self.a = nr1\n",
    "        self.b = nr2\n",
    "\n",
    "    def Add(self):\n",
    "        self.c = self.a + self.b\n",
    "        return self.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3}"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "ins_ex = Example(1, 2)\n",
    "x = ins_ex.Add()\n",
    "ins_ex.__dict__"
   ]
  },
  {
   "source": [
    "### Class attributes vs instance attributes using both mutable and immutable objects"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassVar:\n",
    "\n",
    "    global_immutable_class_variable = 45\n",
    "    global_mutable_class_variable = [1, 2, 3]\n",
    "\n",
    "\n",
    "    def __init__(self, mutable_parameter, immutable_parameter):\n",
    "        self.mutable_instance_attribute = mutable_parameter\n",
    "        self.immutable_instance_attribute = immutable_parameter\n",
    "    \n",
    "    def set_property(self, new_val):\n",
    "        global_immutable_class_variable = new_val\n",
    "        global_mutable_class_variable.append(new_val)\n",
    "        self.immutable_instance_var = 0\n",
    "        self.mutable_instance_var.append(new_val)\n",
    "    \n",
    "    def get_property(self):\n",
    "        try:\n",
    "            print(\"Out of the Excption\")\n",
    "            print(\"global immutable class variable \", global_immutable_class_variable)\n",
    "            print(\"global mutable class variable \", global_mutable_class_variable)\n",
    "        except:\n",
    "            print(\"From Excption\")\n",
    "            print(\"global immutable class variable \", ClassVar.global_immutable_class_variable)\n",
    "            print(\"global mutable class variable \", ClassVar.global_mutable_class_variable)\n",
    "        print(\"immutable instance attribute \", self.immutable_instance_attribute)\n",
    "        print(\"mutable instance attribute \", self.mutable_instance_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1 = ClassVar([10, 20, 30], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "From Excption\nglobal immutable class variable  45\nglobal mutable class variable  [1, 2, 3]\nimmutable instance attribute  100\nmutable instance attribute  [10, 20, 30]\n"
     ]
    }
   ],
   "source": [
    "instance1.get_property()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'mutable_instance_attribute': [10, 20, 30],\n",
       " 'immutable_instance_attribute': 100}"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "instance1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__',\n",
       "              'global_immutable_class_variable': 45,\n",
       "              'global_mutable_class_variable': [1, 2, 3],\n",
       "              '__init__': <function __main__.ClassVar.__init__(self, mutable_parameter, immutable_parameter)>,\n",
       "              'set_property': <function __main__.ClassVar.set_property(self, new_val)>,\n",
       "              'get_property': <function __main__.ClassVar.get_property(self)>,\n",
       "              '__dict__': <attribute '__dict__' of 'ClassVar' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'ClassVar' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "ClassVar.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1.global_mutable_class_variable.append(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1, 2, 3, 40, 40]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "instance1.global_mutable_class_variable"
   ]
  },
  {
   "source": [
    "### Problem-2\n",
    "Performance of Numpy Array vs Python List\n",
    "```Python\n",
    "y_list = tr_y.values.flatten().tolist()\n",
    "sum([1 if y == 5 else 0 for y in y_list]) / len(y_list)\n",
    "```\n",
    "is faster than \n",
    "```\n",
    "arr = tr_y.to_numpy()\n",
    "sum([1 for i in arr if i == 5 ])/arr.__len__()\n",
    "```\n",
    "\n",
    "this happend because of that numpy has to wrap the returned object with a python type (e.g. numpy.float64 or numpy.int64 in this case) which takes time if you're iterating item-by-item1. Further proof of this is demonstrated when iterating -- We see that we're alternating between 2 separate IDs while iterating over the array. This means that python's memory allocator and garbage collector are working overtime to create new objects and then free them.\n",
    "\n",
    "A list doesn't have this memory allocator/garbage collector overhead. The objects in the list already exist as python objects (and they'll still exist after iteration), so neither plays any role in the iteration over a list. \n",
    "\n",
    "[Stackoverflow reference](https://stackoverflow.com/questions/35232406/why-is-a-for-over-a-python-list-faster-than-over-a-numpy-array)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12.3 µs ± 193 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "y_list = tr_y.values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4.55 µs ± 92.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "arr = tr_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = tr_y.values.flatten().tolist()\n",
    "arr = tr_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "54.9 µs ± 1.21 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sum([1 if y == 5 else 0 for y in y_list]) / len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "883 µs ± 48 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sum([1 for i in arr if i == 5 ])/arr.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "131 ns ± 2.69 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a = [[2,3,5],[3,6,2],[1,3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.89 µs ± 50.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a = np.array([[2,3,5],[3,6,2],[1,3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[2,3,5],[3,6,2],[1,3,2]]\n",
    "b = np.array([[2,3,5],[3,6,2],[1,3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "234 ns ± 9.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [i for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.01 µs ± 15.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [i for i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2193455078096"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "id(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462456\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n2193439462960\n"
     ]
    }
   ],
   "source": [
    "for i in range(a.__len__()):\n",
    "    print(id(a[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2193458703240"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1672492672\n1672492704\n1672492736\n1672492768\n1672492800\n1672492832\n1672492864\n1672492896\n1672492928\n1672492960\n1672492992\n1672493024\n1672493056\n1672493088\n1672493120\n1672493152\n1672493184\n1672493216\n1672493248\n1672493280\n1672493312\n1672493344\n1672493376\n1672493408\n1672493440\n1672493472\n1672493504\n1672493536\n1672493568\n1672493600\n1672493632\n1672493664\n"
     ]
    }
   ],
   "source": [
    "for i in range(b.__len__()):\n",
    "    print(id(b[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "sys.getsizeof(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "456 ns ± 10.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#mathimatical operations timing on list vs numpy\n",
    "%timeit a-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}